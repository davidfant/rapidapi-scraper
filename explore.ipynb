{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Sample:\n",
    "  api: dict\n",
    "  endpoint: dict\n",
    "  payload: dict | None\n",
    "\n",
    "def remove_markdown(string: str) -> str:\n",
    "  html = markdown.markdown(string)\n",
    "  return BeautifulSoup(html, features=\"html.parser\").get_text()\n",
    "\n",
    "apis = []\n",
    "for root, dirs, files in os.walk('./data'):\n",
    "  for file in files:\n",
    "    if file.endswith('.json'):\n",
    "      with open(os.path.join(root, file), 'r') as f:\n",
    "        api = json.load(f)\n",
    "        if not api['version']:\n",
    "          continue\n",
    "        apis.append(api)\n",
    "\n",
    "samples = []\n",
    "for api in tqdm(apis):\n",
    "  for endpoint in api['version']['endpoints']:\n",
    "    for payload in endpoint['responsePayloads']:\n",
    "      if not payload['examples'].get('Response'):\n",
    "        continue\n",
    "      payload_data = payload['examples']['Response']['value']\n",
    "      if not isinstance(payload_data, dict) and not isinstance(payload_data, list):\n",
    "        continue\n",
    "      \n",
    "      strings = ''.join([api['name'], api['description'], endpoint['name'], endpoint['description']])\n",
    "      if any('\\u4e00' <= char <= '\\u9fff' for char in strings):\n",
    "        continue\n",
    "      if 'amazon' in strings.lower():\n",
    "        continue\n",
    "\n",
    "      sample = Sample(\n",
    "        api={\n",
    "          'id': api['id'],\n",
    "          'name': remove_markdown(api['name']),\n",
    "          'description': remove_markdown(api['description']),\n",
    "          'slug': api['slugifiedName'],\n",
    "          'category': api['category'],\n",
    "          'score': api['score']['popularityScore'] if api['score'] is not None else None,\n",
    "        },\n",
    "        endpoint={\n",
    "          'id': endpoint['id'],\n",
    "          'route': endpoint['route'],\n",
    "          'method': endpoint['method'],\n",
    "          'name': remove_markdown(endpoint['name']),\n",
    "          'description': remove_markdown(endpoint['description']),\n",
    "          'params': [{\n",
    "            'name': p['name'],\n",
    "            'type': p.get('paramType'),\n",
    "            'description': p.get('description'),\n",
    "            'condition': p['condition'],\n",
    "          } for p in (endpoint['params']['parameters'] if endpoint['params'] else [])],\n",
    "        },\n",
    "        payload={\n",
    "          'name': payload['name'],\n",
    "          'status': payload['statusCode'],\n",
    "          'json': payload_data,\n",
    "        },\n",
    "      )\n",
    "      samples.append(sample)\n",
    "            \n",
    "print(len(samples))\n",
    "\n",
    "# exclude everything that contains amazon in the name\n",
    "# set token limit for JSON to e.g. 3k tokens to prevent e.g. base64 images, unless api score is >9. then limit can be 10k tokens\n",
    "# score > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "dataset = {\n",
    "  'api_name': [],\n",
    "  'api_description': [],\n",
    "  'endpoint_name': [],\n",
    "  'endpoint_description': [],\n",
    "  'response': [],\n",
    "}\n",
    "\n",
    "count = 0\n",
    "for sample in tqdm(samples):\n",
    "  j = json.dumps(sample.payload['json'])\n",
    "  l = len(j)\n",
    "  if l > 50_000:\n",
    "    continue\n",
    "  if len(sample.api['description']) > 500:\n",
    "    continue\n",
    "  if len(sample.endpoint['description']) > 500:\n",
    "    continue\n",
    "  \n",
    "  dataset['api_name'].append(sample.api['name'])\n",
    "  dataset['api_description'].append(sample.api['description'])\n",
    "  dataset['endpoint_name'].append(sample.endpoint['name'])\n",
    "  dataset['endpoint_description'].append(sample.endpoint['description'])\n",
    "  dataset['response'].append(j)\n",
    "\n",
    "dataset = Dataset.from_dict(dataset)\n",
    "print(len(dataset))\n",
    "dataset.push_to_hub('davidfant/rapidapi-example-responses')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import asdict\n",
    "import json_document_splitter as jds\n",
    "\n",
    "idx = 570\n",
    "sample = samples[idx]\n",
    "input_ids = tokenizer.encode(json.dumps(sample.payload['json']))\n",
    "\n",
    "if len(input_ids) > 10_000:\n",
    "  print('too long', len(input_ids))\n",
    "  raise Exception()\n",
    "\n",
    "calculate_weight = lambda x: len(tokenizer.encode(json.dumps(x.value)))\n",
    "\n",
    "graph = jds.create_graph(sample.payload['json'])\n",
    "clusters = jds.sample_clusters(graph, max_weight=512, calculate_weight=calculate_weight)\n",
    "jds.visualize(graph, clusters, calculate_weight=calculate_weight, label_objects_and_arrays=False)\n",
    "\n",
    "# print(len(samples))\n",
    "# print(len([s for s in samples if s.api['score']]))\n",
    "print(len(clusters))\n",
    "print(json.dumps({ 'tokens': len(input_ids), **asdict(sample) }, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
